# Clickbait Detection: Prompting vs Fine-tuning

Dá»± Ã¡n nghiÃªn cá»©u so sÃ¡nh hiá»‡u quáº£ cá»§a **Prompting** vÃ  **Fine-tuning** trong bÃ i toÃ¡n phÃ¡t hiá»‡n clickbait tiáº¿ng Viá»‡t sá»­ dá»¥ng cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ lá»›n (LLMs).

## ğŸ¯ Káº¿t quáº£ chÃ­nh

| PhÆ°Æ¡ng phÃ¡p | MÃ´ hÃ¬nh tá»‘t nháº¥t | Accuracy | Macro F1 | Æ¯u Ä‘iá»ƒm |
|-------------|------------------|----------|----------|---------|
| **Prompting** | Gemma 7B (Few-shot) | **75.6%** | **74.0%** | KhÃ´ng cáº§n training, nhanh |
| **Fine-tuning** | Llama 3.1 8B (Zero-shot) | **85.7%** | **83.2%** | Hiá»‡u suáº¥t cao nháº¥t |

> **Káº¿t luáº­n**: Fine-tuning vá»›i QLoRA vÆ°á»£t trá»™i hÆ¡n prompting ~10% accuracy, Ä‘Ã¡ng giÃ¡ vá»›i chi phÃ­ training há»£p lÃ½.

## ğŸ“‹ Má»¥c lá»¥c

- [Tá»•ng quan](#tá»•ng-quan)
- [Cáº¥u trÃºc dá»± Ã¡n](#cáº¥u-trÃºc-dá»±-Ã¡n)
- [CÃ i Ä‘áº·t](#cÃ i-Ä‘áº·t)
- [Sá»­ dá»¥ng](#sá»­-dá»¥ng)
- [ThÃ­ nghiá»‡m](#thÃ­-nghiá»‡m)
- [Káº¿t quáº£](#káº¿t-quáº£)
- [ÄÃ³ng gÃ³p](#Ä‘Ã³ng-gÃ³p)

## ğŸ¯ Tá»•ng quan

### Má»¥c tiÃªu
- So sÃ¡nh hiá»‡u quáº£ cá»§a **Zero-shot/Few-shot Prompting** vs **Fine-tuning vá»›i QLoRA**
- ÄÃ¡nh giÃ¡ trÃªn dataset clickbait tiáº¿ng Viá»‡t
- PhÃ¢n tÃ­ch trade-off giá»¯a hiá»‡u suáº¥t vÃ  chi phÃ­ tÃ­nh toÃ¡n

### MÃ´ hÃ¬nh Ä‘Æ°á»£c sá»­ dá»¥ng
- **Meta Llama 3.1 8B Instruct**
- **Google Gemma 7B IT**

### PhÆ°Æ¡ng phÃ¡p
1. **Prompting Approaches:**
   - Zero-shot prompting
   - Few-shot prompting (3-6 examples)
   - Improved prompting vá»›i context tá»‘t hÆ¡n

2. **Fine-tuning Approaches:**
   - QLoRA (Quantized Low-Rank Adaptation)
   - 4-bit quantization Ä‘á»ƒ tiáº¿t kiá»‡m memory
   - LoRA rank 16, alpha 32

## ğŸ“ Cáº¥u trÃºc dá»± Ã¡n

```
prompting-finetune/
â”œâ”€â”€ README.md                    # File nÃ y
â”œâ”€â”€ requirements.txt             # Dependencies
â”œâ”€â”€ 
â”œâ”€â”€ src/                        # Source code chÃ­nh
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ experiments/            # CÃ¡c thÃ­ nghiá»‡m
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ clickbait_experiment.py      # ThÃ­ nghiá»‡m chÃ­nh
â”‚   â”‚   â”œâ”€â”€ finetuning_experiment.py     # Fine-tuning vá»›i QLoRA
â”‚   â”‚   â”œâ”€â”€ pretrained_prompting.py      # Zero/Few-shot prompting
â”‚   â”‚   â”œâ”€â”€ pretrained_prompting_improved.py  # Prompting cáº£i tiáº¿n
â”‚   â”‚   â””â”€â”€ evaluate_finetuned_prompting.py   # ÄÃ¡nh giÃ¡ mÃ´ hÃ¬nh
â”‚   â”œâ”€â”€ models/                 # Model utilities
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â””â”€â”€ utils/                  # Utilities
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ data_loader.py      # Data loading utilities
â”‚       â””â”€â”€ metrics.py          # Evaluation metrics
â”‚
â”œâ”€â”€ data/                       # Dá»¯ liá»‡u
â”‚   â”œâ”€â”€ simple_dataset/         # Dataset clickbait
â”‚   â”‚   â”œâ”€â”€ train/              # Training data
â”‚   â”‚   â”œâ”€â”€ val/                # Validation data
â”‚   â”‚   â””â”€â”€ test/               # Test data
â”‚   â””â”€â”€ processed/              # Processed data
â”‚
â”œâ”€â”€ scripts/                    # Scripts cháº¡y thÃ­ nghiá»‡m
â”‚   â”œâ”€â”€ run_experiment.py       # Script test Ä‘Æ¡n giáº£n
â”‚   â”œâ”€â”€ run_improved_evaluation.py  # Evaluation cáº£i tiáº¿n
â”‚   â””â”€â”€ run_quick_test.py       # Quick test
â”‚
â”œâ”€â”€ results/                    # Káº¿t quáº£ thÃ­ nghiá»‡m
â”‚   â”œâ”€â”€ experiments/            # CSV results
â”‚   â”œâ”€â”€ models/                 # Saved models
â”‚   â””â”€â”€ logs/                   # Log files
â”‚
â”œâ”€â”€ docs/                       # Documentation
â””â”€â”€ tests/                      # Unit tests
```

## ğŸš€ CÃ i Ä‘áº·t

### YÃªu cáº§u há»‡ thá»‘ng
- Python 3.8+
- CUDA-capable GPU (khuyáº¿n nghá»‹ 16GB+ VRAM)
- 32GB+ RAM

### CÃ i Ä‘áº·t dependencies

```bash
# Clone repository
git clone <repository-url>
cd prompting-finetune

# Táº¡o virtual environment
python -m venv venv
source venv/bin/activate  # Linux/Mac
# hoáº·c
venv\Scripts\activate     # Windows

# CÃ i Ä‘áº·t packages
pip install -r requirements.txt
```

### Cáº¥u hÃ¬nh Hugging Face
```bash
# ÄÄƒng nháº­p Hugging Face Ä‘á»ƒ truy cáº­p cÃ¡c mÃ´ hÃ¬nh
huggingface-cli login
```

## ğŸ’» Sá»­ dá»¥ng

### 1. Test nhanh há»‡ thá»‘ng
```bash
python scripts/run_experiment.py
```

### 2. Cháº¡y thÃ­ nghiá»‡m Prompting
```bash
# Zero-shot vÃ  Few-shot prompting
python src/experiments/pretrained_prompting.py

# Prompting cáº£i tiáº¿n
python src/experiments/pretrained_prompting_improved.py
```

### 3. Cháº¡y thÃ­ nghiá»‡m Fine-tuning
```bash
# Fine-tuning vá»›i QLoRA
python src/experiments/finetuning_experiment.py
```

### 4. So sÃ¡nh káº¿t quáº£
```bash
# ÄÃ¡nh giÃ¡ vÃ  so sÃ¡nh cÃ¡c phÆ°Æ¡ng phÃ¡p
python src/experiments/evaluate_finetuned_prompting.py
```

## ğŸ§ª ThÃ­ nghiá»‡m

### Dataset
- **Nguá»“n**: Dataset clickbait tiáº¿ng Viá»‡t
- **Tá»•ng kÃ­ch thÆ°á»›c**: 3,414 samples
- **PhÃ¢n chia**:
  - **Train**: 2,389 samples (745 clickbait - 31.2%, 1,644 non-clickbait - 68.8%)
  - **Validation**: 513 samples (160 clickbait - 31.2%, 353 non-clickbait - 68.8%)
  - **Test**: 512 samples (160 clickbait - 31.2%, 352 non-clickbait - 68.8%)
- **Labels**: `clickbait` vÃ  `non-clickbait`
- **Äáº·c Ä‘iá»ƒm**: Dataset cÃ¢n báº±ng vá»›i tá»· lá»‡ clickbait/non-clickbait khoáº£ng 1:2

### Metrics Ä‘Ã¡nh giÃ¡
- **Accuracy**: Äá»™ chÃ­nh xÃ¡c tá»•ng thá»ƒ
- **Precision/Recall/F1**: Cho tá»«ng class
- **Macro F1**: Trung bÃ¬nh F1 cá»§a cÃ¡c class

### Cáº¥u hÃ¬nh thÃ­ nghiá»‡m

#### Prompting
- **Temperature**: 0.1 (deterministic)
- **Max tokens**: 10
- **Few-shot examples**: 3-6 examples

#### Fine-tuning  
- **Method**: QLoRA
- **Quantization**: 4-bit
- **LoRA rank**: 16
- **LoRA alpha**: 32
- **Learning rate**: 2e-4
- **Batch size**: 4
- **Epochs**: 3

## ğŸ“Š Káº¿t quáº£

Káº¿t quáº£ chi tiáº¿t Ä‘Æ°á»£c lÆ°u trong thÆ° má»¥c `results/experiments/`:
- `pretrained_prompting_results_20250712_112415.csv` - Káº¿t quáº£ prompting experiments
- `finetuned_results_20250712_154101.csv` - Káº¿t quáº£ fine-tuning experiments

### Prompting Results (`pretrained_prompting_results_20250712_112415.csv`)

| Model | Experiment | Accuracy | Macro F1 | Clickbait F1 | Non-Clickbait F1 |
|-------|------------|----------|----------|--------------|------------------|
| **Llama 3.1 8B** | Zero-shot | 0.746 | 0.644 | 0.454 | 0.835 |
| **Llama 3.1 8B** | Few-shot | 0.754 | 0.740 | 0.680 | 0.800 |
| **Gemma 7B** | Zero-shot | 0.385 | 0.363 | 0.481 | 0.245 |
| **Gemma 7B** | Few-shot | 0.756 | 0.693 | 0.555 | 0.832 |

### Fine-tuning Results (`finetuned_results_20250712_154101.csv`)

| Model | Experiment | Accuracy | Macro F1 | Clickbait F1 | Non-Clickbait F1 |
|-------|------------|----------|----------|--------------|------------------|
| **Llama 3.1 8B** | Zero-shot | 0.857 | 0.832 | 0.767 | 0.897 |
| **Llama 3.1 8B** | Few-shot | 0.832 | 0.817 | 0.765 | 0.869 |
| **Gemma 7B** | Zero-shot | 0.834 | 0.812 | 0.748 | 0.876 |
| **Gemma 7B** | Few-shot | 0.844 | 0.823 | 0.763 | 0.883 |

### PhÃ¢n tÃ­ch káº¿t quáº£

#### ğŸ† **Fine-tuning vÆ°á»£t trá»™i hÆ¡n Prompting**
- **Accuracy**: Fine-tuning Ä‘áº¡t 83-86% vs Prompting 38-76%
- **Macro F1**: Fine-tuning Ä‘áº¡t 81-83% vs Prompting 36-74%
- **Cáº£i thiá»‡n Ä‘Ã¡ng ká»ƒ** trong viá»‡c phÃ¡t hiá»‡n clickbait

#### ğŸ” **So sÃ¡nh chi tiáº¿t**
| PhÆ°Æ¡ng phÃ¡p | Best Accuracy | Best Macro F1 | Training Time | Memory Usage |
|-------------|---------------|---------------|---------------|--------------|
| **Prompting Zero-shot** | 0.746 (Llama) | 0.644 (Llama) | 0 | Low |
| **Prompting Few-shot** | 0.756 (Gemma) | 0.740 (Llama) | 0 | Low |
| **Fine-tuning Zero-shot** | 0.857 (Llama) | 0.832 (Llama) | ~2 hours | Medium |
| **Fine-tuning Few-shot** | 0.844 (Gemma) | 0.823 (Gemma) | ~2 hours | Medium |

#### ğŸ“ˆ **Insights**
- **Llama 3.1 8B** tá»•ng thá»ƒ tá»‘t hÆ¡n **Gemma 7B** trong prompting
- **Fine-tuning** giÃºp cáº£ hai mÃ´ hÃ¬nh Ä‘áº¡t hiá»‡u suáº¥t tÆ°Æ¡ng Ä‘Æ°Æ¡ng cao
- **Few-shot prompting** cáº£i thiá»‡n Ä‘Ã¡ng ká»ƒ so vá»›i zero-shot (Ä‘áº·c biá»‡t vá»›i Gemma)
- **QLoRA fine-tuning** mang láº¡i káº¿t quáº£ áº¥n tÆ°á»£ng vá»›i chi phÃ­ tÃ­nh toÃ¡n há»£p lÃ½

## ğŸ† Ranking táº¥t cáº£ cÃ¡c phÆ°Æ¡ng phÃ¡p

| Rank | PhÆ°Æ¡ng phÃ¡p | MÃ´ hÃ¬nh | Accuracy | Macro F1 | Clickbait F1 | Non-Clickbait F1 |
|------|-------------|---------|----------|----------|--------------|------------------|
| 1 | Fine-tuning Zero-shot | Llama 3.1 8B | **85.7%** | **83.2%** | 76.7% | 89.7% |
| 2 | Fine-tuning Few-shot | Gemma 7B | 84.4% | 82.3% | 76.3% | 88.3% |
| 3 | Fine-tuning Zero-shot | Gemma 7B | 83.4% | 81.2% | 74.8% | 87.6% |
| 4 | Fine-tuning Few-shot | Llama 3.1 8B | 83.2% | 81.7% | 76.5% | 86.9% |
| 5 | Prompting Few-shot | Gemma 7B | 75.6% | 69.3% | 55.5% | 83.2% |
| 6 | Prompting Few-shot | Llama 3.1 8B | 75.4% | 74.0% | 68.0% | 80.0% |
| 7 | Prompting Zero-shot | Llama 3.1 8B | 74.6% | 64.4% | 45.4% | 83.5% |
| 8 | Prompting Zero-shot | Gemma 7B | 38.5% | 36.3% | 48.1% | 24.5% |

## ğŸ“Š PhÃ¢n tÃ­ch chi tiáº¿t

### Fine-tuning vs Prompting
- **Fine-tuning** vÆ°á»£t trá»™i vá»›i accuracy 83-86% vs prompting 38-76%
- **Cáº£i thiá»‡n lá»›n nháº¥t**: Gemma 7B tá»« 38.5% (zero-shot prompting) lÃªn 84.4% (few-shot fine-tuning)
- **Llama 3.1 8B** á»•n Ä‘á»‹nh hÆ¡n trong prompting, nhÆ°ng cáº£ hai mÃ´ hÃ¬nh Ä‘á»u Ä‘áº¡t hiá»‡u suáº¥t tÆ°Æ¡ng Ä‘Æ°Æ¡ng sau fine-tuning

### Zero-shot vs Few-shot
#### Prompting:
- **Few-shot** cáº£i thiá»‡n Ä‘Ã¡ng ká»ƒ so vá»›i zero-shot
- Gemma 7B: 38.5% â†’ 75.6% (+37.1%)
- Llama 3.1 8B: 74.6% â†’ 75.4% (+0.8%)

#### Fine-tuning:
- **Zero-shot** thÆ°á»ng tá»‘t hÆ¡n few-shot má»™t chÃºt
- CÃ³ thá»ƒ do overfitting vá»›i few-shot examples

### PhÃ¡t hiá»‡n Clickbait vs Non-Clickbait
- **Non-clickbait F1** luÃ´n cao hÆ¡n **Clickbait F1** (do dataset imbalanced)
- Fine-tuning cáº£i thiá»‡n Ä‘Ã¡ng ká»ƒ kháº£ nÄƒng phÃ¡t hiá»‡n clickbait
- Prompting gáº·p khÃ³ khÄƒn vá»›i class clickbait (minority class)

## ğŸ’¡ Insights vÃ  Khuyáº¿n nghá»‹

### Khi nÃ o dÃ¹ng Prompting:
- âœ… Cáº§n káº¿t quáº£ nhanh, khÃ´ng cÃ³ thá»i gian training
- âœ… Dataset nhá» hoáº·c khÃ´ng cÃ³ GPU máº¡nh
- âœ… Prototype hoáº·c proof-of-concept
- âš ï¸ Cháº¥p nháº­n accuracy tháº¥p hÆ¡n ~10%

### Khi nÃ o dÃ¹ng Fine-tuning:
- âœ… Cáº§n hiá»‡u suáº¥t cao nháº¥t
- âœ… CÃ³ GPU vÃ  thá»i gian training (~2 hours)
- âœ… Production system
- âœ… Dataset Ä‘á»§ lá»›n (>1000 samples)

### Lá»±a chá»n mÃ´ hÃ¬nh:
- **Llama 3.1 8B**: Tá»‘t hÆ¡n cho prompting, Ä‘áº·c biá»‡t zero-shot
- **Gemma 7B**: Cáº£i thiá»‡n máº¡nh vá»›i fine-tuning, hiá»‡u suáº¥t tÆ°Æ¡ng Ä‘Æ°Æ¡ng Llama sau fine-tuning
- **QLoRA**: Hiá»‡u quáº£ cho fine-tuning vá»›i memory háº¡n cháº¿

## ğŸ”§ Cáº¥u hÃ¬nh tá»‘t nháº¥t

### Prompting:
```python
# Few-shot vá»›i 3-6 examples
temperature = 0.1
max_new_tokens = 10
model = "meta-llama/Llama-3.1-8B-Instruct"  # cho zero-shot
model = "google/gemma-7b-it"  # cho few-shot
```

### Fine-tuning:
```python
# QLoRA configuration
lora_r = 16
lora_alpha = 32
learning_rate = 2e-4
batch_size = 4
epochs = 3
quantization = "4bit"
```

## ğŸ“… Thá»i gian thÃ­ nghiá»‡m
- **Prompting experiments**: 12/07/2025 11:24
- **Fine-tuning experiments**: 12/07/2025 15:41
- **Total runtime**: ~4 hours (bao gá»“m cáº£ training time)

## ğŸ¤ ÄÃ³ng gÃ³p

1. Fork repository
2. Táº¡o feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to branch (`git push origin feature/AmazingFeature`)
5. Táº¡o Pull Request

## ğŸ“ License

Distributed under the MIT License. See `LICENSE` for more information.

## ğŸ“ LiÃªn há»‡

- **Author**: Nguyen Minh Y   
- **Email**: nguyenminhy7714@gmail.com
- **Project Link**: [https://github.com/blanatole/ViClickbait-2025-Finetune-LLMs](https://github.com/blanatole/ViClickbait-2025-Finetune-LLMs)

## ğŸ™ Acknowledgments

- Hugging Face Transformers
- Meta Llama 3.1
- Google Gemma
- QLoRA paper authors
